{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare dataset and model"
      ],
      "metadata": {
        "id": "lRzI5JOq-q7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8BlmwUGhNBpA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJTY3GmPCyyb",
        "outputId": "345939eb-7748-464b-a8b4-180fa22ad529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "\n",
        "input_size=32\n",
        "num_workers = 2\n",
        "\n",
        "transform_train = transforms.Compose(\n",
        "     [transforms.RandomCrop(32, 4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])])\n",
        "\n",
        "transform_val = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
        "])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "valset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform_val)\n",
        "valloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "classes = ('apples', 'aquarium fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottles',\n",
        "           'bowls', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'cans', 'castle', 'caterpillar', 'cattle', 'chair',\n",
        "           'chimpanzee', 'clock', 'cloud', 'cockroach', 'computer keyboard', 'couch', 'crab', 'crocodile',\n",
        "           'cups', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house',\n",
        "           'kangaroo', 'lamp', 'lawn-mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple', 'motorcycle',\n",
        "           'mountain', 'mouse', 'mushrooms', 'oak', 'oranges', 'orchids', 'otter', 'palm', 'pears', 'pickup truck',\n",
        "           'pine', 'plain', 'plates', 'poppies', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket',\n",
        "           'roses', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel',\n",
        "           'streetcar', 'sunflowers', 'sweet peppers', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor',\n",
        "           'train', 'trout', 'tulips', 'turtle', 'wardrobe', 'whale', 'willow', 'wolf', 'woman', 'worm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04jhqrDn_H1H",
        "outputId": "2d27995f-7049-4242-b583-9a468286f6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define ResNet model\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    \"\"\"Basic Residual Block.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int,\n",
        "        stride: Optional[int] = 1, downsample: Optional[nn.Module] = None\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward Pass.\"\"\"\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"Residual Neural Network.\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes: Optional[int] = 100, in_channels: Optional[int] = 32) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Pre\n",
        "        self.in_channels = in_channels\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, 1, 1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(num_features=32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout2d(p=0.02)\n",
        "\n",
        "        # Basic Blocks\n",
        "        self.conv2_x = nn.Sequential(*[\n",
        "            BasicBlock(32, 32) for i in range(4)\n",
        "        ])\n",
        "\n",
        "        self.conv3_x = nn.Sequential(BasicBlock(\n",
        "            32, 64, 2,\n",
        "            nn.Sequential(nn.Conv2d(32, 64, 3, 2, 1, bias=False), nn.BatchNorm2d(64))\n",
        "        ))\n",
        "\n",
        "        self.conv4_x = nn.Sequential(BasicBlock(\n",
        "            64, 128, 2,\n",
        "            nn.Sequential(nn.Conv2d(64, 128, 3, 2, 1, bias=False), nn.BatchNorm2d(128))\n",
        "        ))\n",
        "\n",
        "        self.conv5_x = nn.Sequential(BasicBlock(\n",
        "            128, 256, 2,\n",
        "            nn.Sequential(nn.Conv2d(128, 256, 3, 2, 1, bias=False), nn.BatchNorm2d(256))\n",
        "        ))\n",
        "\n",
        "        # Post\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=4, stride=1)\n",
        "        self.fc_layer = nn.Linear(256, num_classes)\n",
        "\n",
        "        # initialize weights\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight.data, mode='fan_out')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2_x(x)\n",
        "        x = self.conv3_x(x)\n",
        "        x = self.conv4_x(x)\n",
        "        x = self.conv5_x(x)\n",
        "\n",
        "        x = self.maxpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "YgmFbz_rAjFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "aE7qJmQO_l9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize model\n",
        "\n",
        "net = ResNet()\n",
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uDKCgQj853G",
        "outputId": "a40da019-bbb5-4aee-db67-cf7049b0fe08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (dropout): Dropout2d(p=0.02, inplace=False)\n",
              "  (block32): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (block64): BasicBlock(\n",
              "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (downsample): Sequential(\n",
              "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (block128): BasicBlock(\n",
              "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (downsample): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (block256): BasicBlock(\n",
              "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (downsample): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (maxpool): MaxPool2d(kernel_size=4, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc_layer): Linear(in_features=256, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize loss function and optimizer\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Id1Z9SvhA24M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epoch = 50\n",
        "PATH = './resnet-pro.pth'\n",
        "min_val_loss = np.inf\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epoch):\n",
        "\n",
        "    # training step\n",
        "    running_train_loss = torch.tensor(0.0, device=device)\n",
        "    running_train_acc = torch.tensor(0.0, device=device)\n",
        "    net.train()\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs = data[0].to(device, non_blocking=True)\n",
        "        labels = data[1].to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_train_loss = torch.add(running_train_loss, loss, alpha=inputs.size(0))\n",
        "        running_train_acc = torch.add(\n",
        "                    running_train_acc, torch.sum(preds == labels.data), alpha=1.0/labels.size(0)\n",
        "        )\n",
        "\n",
        "    epoch_train_loss: float = running_train_loss.cpu().detach().numpy() / len(trainloader) / batch_size\n",
        "    epoch_train_acc: float = running_train_acc.cpu().detach().numpy() / len(trainloader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} \\t\\t Training Loss: {epoch_train_loss} Training accuracy: {epoch_train_acc*100:.2f} %\")\n",
        "\n",
        "    # validation step\n",
        "    running_val_loss = torch.tensor(0.0, device=device)\n",
        "    running_val_acc = torch.tensor(0.0, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        net.eval()\n",
        "        for data in valloader:\n",
        "            inputs = data[0].to(device, non_blocking=True)\n",
        "            labels = data[1].to(device, non_blocking=True)\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, pred = torch.max(outputs, dim=1)\n",
        "            running_val_loss = torch.add(\n",
        "                running_val_loss, loss, alpha=inputs.size(0)\n",
        "            )\n",
        "            running_val_acc = torch.add(\n",
        "                running_val_acc, torch.sum(pred == labels.data), alpha= 1.0/labels.size(0)\n",
        "            )\n",
        "\n",
        "    epoch_val_loss: float = running_val_loss.cpu().detach().numpy() / len(testloader) / batch_size\n",
        "    epoch_val_acc: float = running_val_acc.cpu().detach().numpy() / len(testloader)\n",
        "\n",
        "    print(\n",
        "        f\"Validation Loss: {epoch_val_loss} Validation Accuracy: {epoch_val_acc*100:.2f} %\"\n",
        "    )\n",
        "\n",
        "    # save model weights if validation loss decreased\n",
        "    if min_val_loss > epoch_val_loss:\n",
        "        print(\n",
        "            f\"Validation loss decreased({min_val_loss:.6f}--->\\\n",
        "            {epoch_val_loss:.6f})\"\n",
        "        )\n",
        "        min_val_loss = epoch_val_loss\n",
        "        print(f\"Saving model state dict to {PATH}\")\n",
        "        torch.save(net.state_dict(), PATH)\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "5yH4UfnBBIxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}